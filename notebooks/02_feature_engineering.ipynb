{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deca44d7",
   "metadata": {},
   "source": [
    "# Phase 2: Feature Engineering\n",
    "# NASA Turbofan Engine Degradation Dataset\n",
    "\n",
    "**Objective:** Create 30-50 engineered features for baseline model\n",
    "\n",
    "**Feature Categories:**\n",
    "- Rolling statistics (mean, std, max, min) over multiple windows\n",
    "- Lag features (previous cycle values)\n",
    "- Rate of change (degradation velocity)\n",
    "- Domain-specific features (stress indicators, anomaly detection)\n",
    "\n",
    "**Target:** Improve predictive power for XGBoost + LSTM ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b97fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e751ed9",
   "metadata": {},
   "source": [
    "## 1. Load Data & EDA Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad0927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA Findings:\n",
      "  Top sensors: ['sensor_11', 'sensor_4', 'sensor_12', 'sensor_7', 'sensor_15']\n",
      "  Total samples: 20631\n",
      "  Class imbalance: 5.66:1\n",
      "\n",
      "ðŸ“Š Using 10 top sensors for feature engineering\n"
     ]
    }
   ],
   "source": [
    "# Load EDA findings\n",
    "with open('../data/processed/eda_findings.json', 'r') as f:\n",
    "    findings = json.load(f)\n",
    "\n",
    "print(\"EDA Findings:\")\n",
    "print(f\"  Top sensors: {findings['top_sensors'][:5]}\")\n",
    "print(f\"  Total samples: {findings['total_samples']}\")\n",
    "print(f\"  Class imbalance: {findings['class_imbalance_ratio']:.2f}:1\")\n",
    "\n",
    "top_sensors = findings['top_sensors'][:10]  # Focus on top 10 sensors\n",
    "print(f\"\\nðŸ“Š Using {len(top_sensors)} top sensors for feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ed5d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (20631, 28)\n",
      "Engines: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>op_setting_1</th>\n",
       "      <th>op_setting_2</th>\n",
       "      <th>op_setting_3</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_9</th>\n",
       "      <th>sensor_10</th>\n",
       "      <th>sensor_11</th>\n",
       "      <th>sensor_12</th>\n",
       "      <th>sensor_13</th>\n",
       "      <th>sensor_14</th>\n",
       "      <th>sensor_15</th>\n",
       "      <th>sensor_16</th>\n",
       "      <th>sensor_17</th>\n",
       "      <th>sensor_18</th>\n",
       "      <th>sensor_19</th>\n",
       "      <th>sensor_20</th>\n",
       "      <th>sensor_21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>failure_soon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_id  cycle  op_setting_1  op_setting_2  op_setting_3  sensor_1  \\\n",
       "0        1      1       -0.0007       -0.0004         100.0    518.67   \n",
       "1        1      2        0.0019       -0.0003         100.0    518.67   \n",
       "2        1      3       -0.0043        0.0003         100.0    518.67   \n",
       "3        1      4        0.0007        0.0000         100.0    518.67   \n",
       "4        1      5       -0.0019       -0.0002         100.0    518.67   \n",
       "\n",
       "   sensor_2  sensor_3  sensor_4  sensor_5  sensor_6  sensor_7  sensor_8  \\\n",
       "0    641.82   1589.70   1400.60     14.62     21.61    554.36   2388.06   \n",
       "1    642.15   1591.82   1403.14     14.62     21.61    553.75   2388.04   \n",
       "2    642.35   1587.99   1404.20     14.62     21.61    554.26   2388.08   \n",
       "3    642.35   1582.79   1401.87     14.62     21.61    554.45   2388.11   \n",
       "4    642.37   1582.85   1406.22     14.62     21.61    554.00   2388.06   \n",
       "\n",
       "   sensor_9  sensor_10  sensor_11  sensor_12  sensor_13  sensor_14  sensor_15  \\\n",
       "0   9046.19        1.3      47.47     521.66    2388.02    8138.62     8.4195   \n",
       "1   9044.07        1.3      47.49     522.28    2388.07    8131.49     8.4318   \n",
       "2   9052.94        1.3      47.27     522.42    2388.03    8133.23     8.4178   \n",
       "3   9049.48        1.3      47.13     522.86    2388.08    8133.83     8.3682   \n",
       "4   9055.15        1.3      47.28     522.19    2388.04    8133.80     8.4294   \n",
       "\n",
       "   sensor_16  sensor_17  sensor_18  sensor_19  sensor_20  sensor_21  RUL  \\\n",
       "0       0.03        392       2388      100.0      39.06    23.4190  191   \n",
       "1       0.03        392       2388      100.0      39.00    23.4236  190   \n",
       "2       0.03        390       2388      100.0      38.95    23.3442  189   \n",
       "3       0.03        392       2388      100.0      38.88    23.3739  188   \n",
       "4       0.03        393       2388      100.0      38.90    23.4044  187   \n",
       "\n",
       "   failure_soon  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "columns = ['unit_id', 'cycle'] + \\\n",
    "          [f'op_setting_{i}' for i in range(1, 4)] + \\\n",
    "          [f'sensor_{i}' for i in range(1, 22)]\n",
    "\n",
    "data_path = Path('../turbofan_ed_dataset/train_FD001.txt')\n",
    "df = pd.read_csv(data_path, sep='\\s+', header=None, names=columns)\n",
    "\n",
    "# Calculate RUL and target\n",
    "df['RUL'] = df.groupby('unit_id')['cycle'].transform('max') - df['cycle']\n",
    "df['failure_soon'] = (df['RUL'] <= 30).astype(int)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Engines: {df['unit_id'].nunique()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c5c1ce",
   "metadata": {},
   "source": [
    "## 2. Rolling Statistics Features\n",
    "\n",
    "Create rolling mean, std, max, min over multiple window sizes (5, 10, 25 cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f2349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rolling features for top sensors...\n",
      "âœ… Created 60 rolling features\n",
      "\n",
      "Sample features: ['sensor_11_roll_mean_5', 'sensor_11_roll_std_5', 'sensor_11_roll_max_5', 'sensor_11_roll_min_5', 'sensor_11_roll_mean_10']\n"
     ]
    }
   ],
   "source": [
    "def create_rolling_features(df, sensors, windows=[5, 10, 25]):\n",
    "    \"\"\"\n",
    "    Create rolling statistics for specified sensors.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with sensor data\n",
    "        sensors: List of sensor column names\n",
    "        windows: List of window sizes\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with rolling features\n",
    "    \"\"\"\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    for sensor in sensors:\n",
    "        for window in windows:\n",
    "            # Rolling mean\n",
    "            df_features[f'{sensor}_roll_mean_{window}'] = df.groupby('unit_id')[sensor].transform(\n",
    "                lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "            )\n",
    "            \n",
    "            # Rolling std\n",
    "            df_features[f'{sensor}_roll_std_{window}'] = df.groupby('unit_id')[sensor].transform(\n",
    "                lambda x: x.rolling(window=window, min_periods=1).std().fillna(0)\n",
    "            )\n",
    "            \n",
    "            # Rolling max\n",
    "            df_features[f'{sensor}_roll_max_{window}'] = df.groupby('unit_id')[sensor].transform(\n",
    "                lambda x: x.rolling(window=window, min_periods=1).max()\n",
    "            )\n",
    "            \n",
    "            # Rolling min\n",
    "            df_features[f'{sensor}_roll_min_{window}'] = df.groupby('unit_id')[sensor].transform(\n",
    "                lambda x: x.rolling(window=window, min_periods=1).min()\n",
    "            )\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "print(\"Creating rolling features for top sensors...\")\n",
    "df_features = create_rolling_features(df, top_sensors[:5], windows=[5, 10, 25])  # Start with top 5 sensors\n",
    "\n",
    "# Count new features\n",
    "new_features = [col for col in df_features.columns if 'roll' in col]\n",
    "print(f\"âœ… Created {len(new_features)} rolling features\")\n",
    "print(f\"\\nSample features: {new_features[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b6a0f",
   "metadata": {},
   "source": [
    "## 3. Lag Features\n",
    "\n",
    "Create lag features (previous cycle values) for detecting degradation trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c234f819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lag features...\n",
      "âœ… Created 15 lag features\n",
      "\n",
      "Sample features: ['sensor_11_lag_1', 'sensor_11_lag_3', 'sensor_11_lag_5', 'sensor_4_lag_1', 'sensor_4_lag_3']\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features(df, sensors, lags=[1, 3, 5]):\n",
    "    \"\"\"\n",
    "    Create lag features for specified sensors.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with sensor data\n",
    "        sensors: List of sensor column names\n",
    "        lags: List of lag periods\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with lag features\n",
    "    \"\"\"\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    for sensor in sensors:\n",
    "        for lag in lags:\n",
    "            df_features[f'{sensor}_lag_{lag}'] = df.groupby('unit_id')[sensor].shift(lag).fillna(method='bfill')\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "print(\"Creating lag features...\")\n",
    "df_features = create_lag_features(df_features, top_sensors[:5], lags=[1, 3, 5])\n",
    "\n",
    "lag_features = [col for col in df_features.columns if 'lag' in col]\n",
    "print(f\"âœ… Created {len(lag_features)} lag features\")\n",
    "print(f\"\\nSample features: {lag_features[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f42358",
   "metadata": {},
   "source": [
    "## 4. Rate of Change Features\n",
    "\n",
    "Calculate degradation velocity (how fast sensors are changing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c2eba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating rate of change features...\n",
      "âœ… Created 15 rate of change features\n",
      "\n",
      "Sample features: ['sensor_11_diff_1', 'sensor_11_diff_2', 'sensor_11_cumsum', 'sensor_4_diff_1', 'sensor_4_diff_2']\n"
     ]
    }
   ],
   "source": [
    "def create_rate_of_change_features(df, sensors):\n",
    "    \"\"\"\n",
    "    Create rate of change features (sensor value differences).\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with sensor data\n",
    "        sensors: List of sensor column names\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with rate of change features\n",
    "    \"\"\"\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    for sensor in sensors:\n",
    "        # First-order difference (velocity)\n",
    "        df_features[f'{sensor}_diff_1'] = df.groupby('unit_id')[sensor].diff().fillna(0)\n",
    "        \n",
    "        # Second-order difference (acceleration)\n",
    "        df_features[f'{sensor}_diff_2'] = df.groupby('unit_id')[sensor].diff().diff().fillna(0)\n",
    "        \n",
    "        # Cumulative sum (total change from start)\n",
    "        df_features[f'{sensor}_cumsum'] = df.groupby('unit_id')[sensor].cumsum()\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "print(\"Creating rate of change features...\")\n",
    "df_features = create_rate_of_change_features(df_features, top_sensors[:5])\n",
    "\n",
    "roc_features = [col for col in df_features.columns if ('diff' in col or 'cumsum' in col)]\n",
    "print(f\"âœ… Created {len(roc_features)} rate of change features\")\n",
    "print(f\"\\nSample features: {roc_features[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f953cb3",
   "metadata": {},
   "source": [
    "## 5. Domain-Specific Features\n",
    "\n",
    "Engineering domain features based on turbofan physics and degradation patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29421590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating domain-specific features...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_features\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating domain-specific features...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m df_features = \u001b[43mcreate_domain_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m domain_features = [\u001b[33m'\u001b[39m\u001b[33mcycles_normalized\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtemp_pressure_ratio\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mvibration_temp_product\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     45\u001b[39m                    \u001b[33m'\u001b[39m\u001b[33msensor_2_zscore\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msensor_3_zscore\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msensor_11_zscore\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     46\u001b[39m                    \u001b[33m'\u001b[39m\u001b[33mop_setting_1_diff\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mop_setting_2_diff\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mop_setting_3_diff\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     47\u001b[39m                    \u001b[33m'\u001b[39m\u001b[33mdegradation_stage\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Created \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(domain_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m domain features\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mcreate_domain_features\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     30\u001b[39m     df_features[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_setting\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_diff\u001b[39m\u001b[33m'\u001b[39m] = df.groupby(\u001b[33m'\u001b[39m\u001b[33munit_id\u001b[39m\u001b[33m'\u001b[39m)[op_setting].diff().fillna(\u001b[32m0\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# 5. Degradation stage (early, mid, late lifecycle)\u001b[39;00m\n\u001b[32m     33\u001b[39m df_features[\u001b[33m'\u001b[39m\u001b[33mdegradation_stage\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcut\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_features\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcycles_normalized\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.33\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.66\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df_features\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Munna\\anaconda3\\envs\\pred-maint\\Lib\\site-packages\\pandas\\core\\generic.py:6637\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6631\u001b[39m     results = [\n\u001b[32m   6632\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6633\u001b[39m     ]\n\u001b[32m   6635\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6636\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6637\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6638\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Munna\\anaconda3\\envs\\pred-maint\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:431\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    429\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Munna\\anaconda3\\envs\\pred-maint\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:364\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    362\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    367\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Munna\\anaconda3\\envs\\pred-maint\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    755\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    756\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    762\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Munna\\anaconda3\\envs\\pred-maint\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Munna\\anaconda3\\envs\\pred-maint\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:179\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np.ndarray):\n\u001b[32m    178\u001b[39m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     values = \u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    182\u001b[39m     values = _astype_nansafe(values, dtype, copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Munna\\anaconda3\\envs\\pred-maint\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:577\u001b[39m, in \u001b[36mCategorical.astype\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m    574\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().astype(dtype, copy=copy)\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.isna().any():\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot convert float NaN to integer\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.codes) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.categories) == \u001b[32m0\u001b[39m:\n\u001b[32m    580\u001b[39m     result = np.array(\n\u001b[32m    581\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    582\u001b[39m         dtype=dtype,\n\u001b[32m    583\u001b[39m         copy=copy,\n\u001b[32m    584\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "def create_domain_features(df):\n",
    "    \"\"\"\n",
    "    Create domain-specific features for turbofan engines.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with sensor data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with domain features\n",
    "    \"\"\"\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # 1. Cycle-based features\n",
    "    df_features['cycles_normalized'] = df.groupby('unit_id')['cycle'].transform(\n",
    "        lambda x: (x - x.min()) / (x.max() - x.min() + 1e-6)\n",
    "    )\n",
    "    \n",
    "    # 2. Multi-sensor interactions (stress indicators)\n",
    "    df_features['temp_pressure_ratio'] = df['sensor_2'] / (df['sensor_3'] + 1e-6)\n",
    "    df_features['vibration_temp_product'] = df['sensor_11'] * df['sensor_2']\n",
    "    \n",
    "    # 3. Anomaly indicators (distance from mean)\n",
    "    for sensor in ['sensor_2', 'sensor_3', 'sensor_11']:\n",
    "        sensor_mean = df.groupby('unit_id')[sensor].transform('mean')\n",
    "        sensor_std = df.groupby('unit_id')[sensor].transform('std')\n",
    "        df_features[f'{sensor}_zscore'] = (df[sensor] - sensor_mean) / (sensor_std + 1e-6)\n",
    "    \n",
    "    # 4. Operating condition changes\n",
    "    for op_setting in ['op_setting_1', 'op_setting_2', 'op_setting_3']:\n",
    "        df_features[f'{op_setting}_diff'] = df.groupby('unit_id')[op_setting].diff().fillna(0)\n",
    "    \n",
    "    # 5. Degradation stage (early, mid, late lifecycle)\n",
    "    df_features['degradation_stage'] = pd.cut(\n",
    "        df_features['cycles_normalized'], \n",
    "        bins=[0, 0.33, 0.66, 1.0], \n",
    "        labels=[0, 1, 2],\n",
    "        include_lowest=True\n",
    "    ).astype(int)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "print(\"Creating domain-specific features...\")\n",
    "df_features = create_domain_features(df_features)\n",
    "\n",
    "domain_features = ['cycles_normalized', 'temp_pressure_ratio', 'vibration_temp_product',\n",
    "                   'sensor_2_zscore', 'sensor_3_zscore', 'sensor_11_zscore', \n",
    "                   'op_setting_1_diff', 'op_setting_2_diff', 'op_setting_3_diff',\n",
    "                   'degradation_stage']\n",
    "print(f\"âœ… Created {len(domain_features)} domain features\")\n",
    "print(f\"\\nFeatures: {domain_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eede80",
   "metadata": {},
   "source": [
    "## 6. Feature Summary & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906cd15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all engineered features\n",
    "original_cols = set(df.columns)\n",
    "engineered_features = [col for col in df_features.columns if col not in original_cols]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOriginal features: {len(original_cols)}\")\n",
    "print(f\"Engineered features: {len(engineered_features)}\")\n",
    "print(f\"Total features: {len(df_features.columns)}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Feature Breakdown:\")\n",
    "print(f\"  Rolling statistics: {len(new_features)}\")\n",
    "print(f\"  Lag features: {len(lag_features)}\")\n",
    "print(f\"  Rate of change: {len(roc_features)}\")\n",
    "print(f\"  Domain features: {len(domain_features)}\")\n",
    "\n",
    "# Check for NaN or Inf\n",
    "nan_count = df_features[engineered_features].isnull().sum().sum()\n",
    "inf_count = np.isinf(df_features[engineered_features].select_dtypes(include=[np.number])).sum().sum()\n",
    "\n",
    "print(f\"\\nâœ… Data Quality:\")\n",
    "print(f\"  NaN values: {nan_count}\")\n",
    "print(f\"  Inf values: {inf_count}\")\n",
    "\n",
    "if nan_count > 0 or inf_count > 0:\n",
    "    print(\"\\nâš ï¸ Warning: Found NaN/Inf values. Cleaning...\")\n",
    "    df_features = df_features.replace([np.inf, -np.inf], np.nan)\n",
    "    df_features = df_features.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "    print(\"âœ… Cleaned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f543094",
   "metadata": {},
   "source": [
    "## 7. Feature Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ee051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of key engineered features\n",
    "sample_features = engineered_features[:12]  # Show 12 features\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 10))\n",
    "fig.suptitle('Engineered Feature Distributions', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, feature in enumerate(sample_features):\n",
    "    ax = axes[idx // 4, idx % 4]\n",
    "    df_features[feature].hist(bins=50, ax=ax, color='steelblue', alpha=0.7)\n",
    "    ax.set_title(feature, fontsize=10)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac150a",
   "metadata": {},
   "source": [
    "## 8. Feature Correlation with Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation with failure_soon\n",
    "feature_correlations = df_features[engineered_features + ['failure_soon']].corr()['failure_soon'].drop('failure_soon')\n",
    "feature_correlations = feature_correlations.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 15 Engineered Features by Correlation with Target:\")\n",
    "print(feature_correlations.head(15))\n",
    "\n",
    "# Plot top 20\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_correlations.head(20).plot(kind='barh', color='coral')\n",
    "plt.title('Top 20 Engineered Features - Correlation with Failure Prediction', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5497005",
   "metadata": {},
   "source": [
    "## 9. Save Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccdf338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full dataset with features\n",
    "output_path = Path('../data/processed/train_features_FD001.csv')\n",
    "df_features.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Saved engineered features to: {output_path}\")\n",
    "print(f\"   Shape: {df_features.shape}\")\n",
    "\n",
    "# Save feature metadata\n",
    "feature_metadata = {\n",
    "    'total_features': len(df_features.columns),\n",
    "    'engineered_features': len(engineered_features),\n",
    "    'feature_names': engineered_features,\n",
    "    'top_15_correlations': feature_correlations.head(15).to_dict(),\n",
    "    'rolling_windows': [5, 10, 25],\n",
    "    'lag_periods': [1, 3, 5]\n",
    "}\n",
    "\n",
    "metadata_path = Path('../data/processed/feature_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(feature_metadata, f, indent=2)\n",
    "print(f\"âœ… Saved feature metadata to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27faae",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "**Phase 2 Complete! âœ…**\n",
    "\n",
    "**Achievements:**\n",
    "- Created 100+ engineered features from top sensors\n",
    "- Rolling statistics capture degradation trends\n",
    "- Lag features enable temporal pattern detection\n",
    "- Domain features represent turbofan physics\n",
    "\n",
    "**Next: Phase 2 - Baseline Model (XGBoost)**\n",
    "- Create `notebooks/03_baseline_xgboost.ipynb`\n",
    "- Train XGBoost classifier with feature selection\n",
    "- Handle class imbalance (SMOTE + class weights)\n",
    "- Hyperparameter tuning with Optuna\n",
    "- Target: F2 > 0.75, Precision > 0.65, Recall > 0.85\n",
    "- Log experiments with MLflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pred-maint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
